{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320d0758",
   "metadata": {},
   "source": [
    "# Reporting : wragle_report\n",
    "**- Create a _300-600 word written report_ called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e4f06",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In those cells, we gathered all three pieces of data for this project and loaded them in the notebook.\n",
    "\n",
    "\n",
    "- We directly downloaded the WeRateDogs Twitter archive data called \"twitter_archive_enhanced.csv\" and loaded it to `archive_df` dataset.\n",
    "\n",
    "\n",
    "- We used the Requests library to download the tweet image prediction called \"image_predictions.tsv\" and loaded it to `predictions_df` dataset.\n",
    "\n",
    "\n",
    "- And we was unable to query additional data via the Twitter API but we successful extracted `tweet_df` dataset from the \"tweet_json.txt\" file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327f4fa",
   "metadata": {},
   "source": [
    "## Assessing Data\n",
    "In this section, we detected and documented fifteen (16) quality issues and five (2) tidiness issue. We had to use both visual assessment and programmatic assessement to assess the data.\n",
    "\n",
    "Here are the steps of the programmatic assessement :\n",
    "\n",
    "\n",
    "- The opening of the three first datasets `archive_df`, `predictions_df` and `tweet_df`.\n",
    "\n",
    "\n",
    "- The extracting of the `user_df` dataset from the `tweet_df` one and opening it. Then, we found that there was only one user that was repeated several times.\n",
    "\n",
    "\n",
    "- The finding of informations about the first three datasets.\n",
    "\n",
    "\n",
    "- The finding of their descriptions.\n",
    "\n",
    "\n",
    "- The looking for their duplicate datas, those which are null (not-assigned number) and those which are repeated.\n",
    "\n",
    "\n",
    "- The looking for tweet witch are not about dogs.\n",
    "\n",
    "\n",
    "- And the looking for retweets.\n",
    "\n",
    "So we paid attention to the key point of this section when we accessed the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68193ed",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "In this section, we starting with making a copy of the original data before cleaning. We applied the three (3) other key points of **Assessing Data** section. \n",
    "\n",
    "Here are the steps of the programmatic cleaning :\n",
    "\n",
    "\n",
    "- The replacing of all the null values with the empty object ('None') in `archive_clean` and `tweet_clean` datasets.\n",
    "\n",
    "\n",
    "- The redefining of the type of some columns in all the three datasets.\n",
    "\n",
    "\n",
    "- The removing of link's tags and range brackets in the values of some columns in `archive_clean` and `tweet_clean` datasets.\n",
    "\n",
    "\n",
    "- The redefining of strings as titles in some columns values in all the three datasets.\n",
    "\n",
    "\n",
    "- The removing of inappropriate (dirty or empty) columns in `tweet_clean` dataset.\n",
    "\n",
    "\n",
    "- The renaming of some columns in `tweet_clean` dataset.\n",
    "\n",
    "\n",
    "- The spliting of one column into two others in `tweet_clean` dataset.\n",
    "\n",
    "\n",
    "- And the merging of the three datasets together.\n",
    "\n",
    "We cleaned all of the fifteen (16) quality and the five (2) tidiness issues, we documented while assessing. The result was a high-quality and tidy master DataFrame saved to a CSV file named \"twitter_archive_master.csv\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python_3.6] *",
   "language": "python",
   "name": "conda-env-Python_3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
